{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKmaSCp49KMJstsiX7d14E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArmanBehi/Autoencoder_cFOS/blob/main/cFOS_Denoise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "uAcbBzvw4V-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# NEW! for getting summary info on models\n",
        "from torchsummary import summary\n",
        "\n",
        "#For importing images\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats('svg')"
      ],
      "metadata": {
        "id": "VQn8ETYjKsnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Google Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "6B9BlBXr4eoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AL8f4H6z4fWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Training data\n",
        "The images must be ordered as follow:\n",
        "\n",
        "  parent folder:\n",
        "\n",
        "       Group1\n",
        "       .\n",
        "       .\n",
        "       .\n",
        "       Group2\n",
        "       .\n",
        "       .\n",
        "       .\n",
        "\n",
        "If you have modified images (removed noise by user), you could also enter that, otherweise leave it empty.\n",
        "Also please import number of epochs."
      ],
      "metadata": {
        "id": "_oa8jVAu4om2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# Define CSS styles for the input box\n",
        "input_style = \"\"\"\n",
        "    border: 2px solid #0074D9;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "    font-size: 16px;\n",
        "    width: 300px;\n",
        "    outline: none;\n",
        "    margin: 10px;\n",
        "\"\"\"\n",
        "\n",
        "# Display an input box with the specified style\n",
        "input_html = f'<input style=\"{input_style}\" placeholder=\"Enter your input here\" id=\"input-box\">'\n",
        "display(HTML(input_html))\n",
        "\n",
        "# Get user input\n",
        "data_folder= input(\"Enter your the path of your Original images: \")"
      ],
      "metadata": {
        "id": "L3BozZNz4pV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Uploading images"
      ],
      "metadata": {
        "id": "mugdQRsC40k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predefines image uploading pixel\n",
        "imgSize = 1000\n",
        "\n",
        "###----------data_folder------------\n",
        "# Define the transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((imgSize, imgSize)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create a custom dataset using ImageFolder and apply the transformation\n",
        "custom_dataset = datasets.ImageFolder(root=data_folder, transform=transform)\n",
        "\n",
        "# Create a DataLoader to iterate through the dataset\n",
        "data_loader = DataLoader(custom_dataset, batch_size=len(custom_dataset), shuffle=False)\n",
        "\n",
        "# Iterate through the DataLoader to get images and labels\n",
        "for images, labels in data_loader:\n",
        "    # images will be a tensor of shape (batch_size, 3, imgSize, imgSize)\n",
        "    # labels will be a tensor of shape (batch_size,)\n",
        "    pass\n",
        "\n",
        "##------------------ Display images in Colab\n",
        "fig, axs = plt.subplots(3, 2, figsize=(7, 6))\n",
        "\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    whichpic = np.random.randint(len(images))  # Randomly choose an index\n",
        "    image = np.squeeze(images[whichpic, :, :, :])  # Access the first (and only) channel\n",
        "\n",
        "    ax.imshow(image.permute(1, 2, 0), vmin=0, vmax=1)\n",
        "    ax.set_title('Class %s' % int(labels[whichpic].item()))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XPFs-zRr41R0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}